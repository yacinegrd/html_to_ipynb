{"metadata": {"kernelspec": {"display_name": "base", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9.16"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# TP- D\u00e9monstration du filtrage et de la manipulation du Spectrogramme d'un signal de parole[\u00b6](#TP--D%C3%A9monstration-du-filtrage-et-de-la-manipulation-du-Spectrogramme-d'un-signal-de-parole)\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## I. Fonctions utiles pour le calcul du spectrogramme et le filtrage[\u00b6](#I.-Fonctions-utiles-pour-le-calcul-du-spectrogramme-et-le-filtrage)\n\n"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import wavfile\nfrom IPython.display import Audio, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n#Fen\u00eatre de hamming\ndef hamming(T): return 0.54-0.46*np.cos(2*np.pi*np.arange(T)/(T-1))\n\n#Calcul du spectre amplitude et phase du signal data, taille de la fenetre=T, pas=p\n#mettre pre=True dans l'appel pour activer la pr\u00e9accentuation\n#mettre ham=True pour activer le fen\u00eatrage par hamming\n#Tfft=taille de la fft, si > T le z\u00e9ro padding sera activ\u00e9(voir cours acoustique)\ndef spectrogram(data,fs,T=512,p=32,pre=False,ham=True,Tfft=None,norm=True):\n    if Tfft is None: Tfft=T #si la taille de la fft n'est pas sp\u00e9cifi\u00e9e prendre Tfft=T        \n    if norm: data=(data-np.mean(data))/np.std(data) #normaliser le signal sur son \u00e9cart type\n    \n    if pre: data[1:]-0.97*data[:-1]      #pr\u00e9accentuation\n    s=[data[i:i+T] for i in range(0,len(data)-T,p)] # fen\u00eatrage\n    if ham : s=s*hamming(T)          # multiplication par hamming            \n    s=np.fft.fft(s,Tfft)                 #Transform\u00e9e de Fourier\n    s=s[:,:int(Tfft/2)]                  #couper le spectre en 2 pour \u00e9liminer l'effet mirroir\n    \n    #retourner les spectres d'amplitude et de phase\n    return {\"ampl\": np.abs(s), \"phase\": np.angle(s), \"fs\":fs, \"duree\":len(data)/fs, \"T\": T, \"p\": p, \"Tfft\": Tfft}\n\n\n#Cette fonction affiche un spectrogramme d'amplitude\ndef afficher(spec):\n    fig, ax1 = plt.subplots()\n    ax2 = ax1.twinx()\n    ax3 = ax1.twiny()\n    freq=np.linspace(0, spec[\"fs\"]/2, int(spec[\"Tfft\"]/2)) #labels de l'axe des fr\u00e9quences\n    temps=np.linspace(0, spec[\"duree\"], len(spec[\"ampl\"])) #labels de l'axe du temps\n    ax1.pcolormesh(temps, freq, np.log(spec[\"ampl\"]+1).T, cmap='gray_r')  #afficher le spectre avec correction des axes\n    ax1.set_ylabel('Fr\u00e9quence (Hz)')\n    ax1.set_xlabel('Temps (sec)')\n    ax2.set_yticks(np.round(ax2.get_yticks()*int(spec[\"Tfft\"]/2)))\n    ax2.set_ylabel('Indices des colonnes dans la matrice spec')\n    ax3.set_xticks(np.round(ax3.get_xticks()*len(spec[\"ampl\"])))\n    ax3.set_xlabel('Indices des lignes dans la matrice spec')\n    plt.show()\n    \n\n#Retour \u00e0 partir de l'amplitude et de la phase au signal temporel \n#Ne pas utiliser la pr\u00e9accentuation si vous voulez utiliser cette fonction\ndef spec2wav(spec):\n    p=spec[\"p\"]; T=spec[\"T\"]\n    ne=(len(spec[\"ampl\"])-1)*p+T  #estimation le nombre d'\u00e9chantillons du signal\n    signal=np.zeros(ne)  #initialiser le signal par des z\u00e9ros \n    trams=np.zeros(ne)  #initialiser le nombre de trames par des z\u00e9ros \n    \n    temp=spec[\"ampl\"]*np.exp(1j*spec[\"phase\"]) #recombiner l'amplitude avec la phase (nombre complexe)\n    temp=np.fft.ifft(temp, spec[\"Tfft\"]) #retour au domaine temporel par une fft inverse\n    temp=np.real(temp) #ne garder que la partie r\u00e9elle\n    \n    for i in range(len(temp)): #fen\u00eatrage inverse\n        signal[i*p:i*p+T]+=temp[i,:T]\n        trams[i*p:i*p+T]+=1\n\n    return signal/trams, spec[\"fs\"] #retourner le signal reconstitu\u00e9 et la fr\u00e9quence d'\u00e9chantillonnage", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "#### Chargement d'un fichier wav et affichage de son spectrogramme[\u00b6](#Chargement-d'un-fichier-wav-et-affichage-de-son-spectrogramme)\n\n"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "source": "dataset_path=\"Desktop\\\\TP dataset\\\\dataset\\\\\" #le chemin vers le dataset\nfilename=\"7_george_0.wav\" #le nom du fichier \u00e0 charger\n\nprint('Chargement de :', filename)#chargement d'un fichier audio wav\nfs, data = wavfile.read(dataset_path+filename) #fs: fr\u00e9quence d'\u00e9chantillonnage \n\nprint('Freq \u00e9chantillonnage:',fs,'Hz, dur\u00e9e:',len(data)/fs,'sec')\ndisplay(Audio(data,rate=fs))\nplt.plot(np.arange(len(data))/fs,data); plt.show() #affichage du signal temporel\n\nspec=spectrogram(data, fs, T=256, Tfft=1025) #calcul du spectrogramme \nafficher(spec)  #affichage du spectrogramme", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "#### Reconvertir le spectrogramme en signal temporel[\u00b6](#Reconvertir-le-spectrogramme-en-signal-temporel)\n\n"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "source": "newdata, fs= spec2wav(spec)\ndisplay(Audio(newdata,rate=fs))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## II. Filtrage[\u00b6](#II.-Filtrage)\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Filtre passe bas[\u00b6](#Filtre-passe-bas)\n\n"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "source": "spec=spectrogram(data, fs, T=256, Tfft=1024) #calcul et affichage d'un spectrogramme avec fen\u00eatre de hamming\nspec[\"ampl\"][:,128:]=0  #annuler toutes les fr\u00e9quences > 1000Hz\nafficher(spec) #affichage du spectrogramme\nnewdata, fs= spec2wav(spec)  #retour au domaine temporel\ndisplay(Audio(newdata,rate=fs)) #\u00e9couter le r\u00e9sultat", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "#### Filtre passe haut[\u00b6](#Filtre-passe-haut)\n\n"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "source": "spec=spectrogram(data, fs, T=256, Tfft=1024) #calcul et affichage d'un spectrogramme avec fen\u00eatre de hamming\nspec[\"ampl\"][:,:256]=0  #annuler toutes les fr\u00e9quences < 2000Hz\nafficher(spec) #affichage du spectrogramme\nnewdata, fs= spec2wav(spec)  #retour au domaine temporel\ndisplay(Audio(newdata,rate=fs)) #\u00e9couter le r\u00e9sultat", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "#### Filtre passe bande[\u00b6](#Filtre-passe-bande)\n\n"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "source": "spec=spectrogram(data, fs, T=256, Tfft=1024) #calcul et affichage d'un spectrogramme avec fen\u00eatre de hamming\nspec[\"ampl\"][:,:128]=0  #annuler toutes les fr\u00e9quences < 1000Hz\nspec[\"ampl\"][:,256:]=0  #annuler toutes les fr\u00e9quences > 2000Hz\nafficher(spec) #affichage du spectrogramme\nnewdata, fs= spec2wav(spec)  #retour au domaine temporel\ndisplay(Audio(newdata,rate=fs)) #\u00e9couter le r\u00e9sultat", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Questions[\u00b6](#Questions)\n\n**Q1.** Essayez les filtres en haut sur les mots two, four, seven, eight et notez les phon\u00e8mes qui sont affect\u00e9s par le filtrage.\n\n**Q2.** Chargez le fichier mots\\_bruit.wav et essayez d'y filtrer le bruit avec la m\u00e9thode de soustraction spectrale.\n\n"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "source": "fs, data = wavfile.read(\"mots_bruit.wav\") #chargement d'un fichier audio wav\nprint('Signal orginal: Freq \u00e9chantillonnage:',fs,'Hz, dur\u00e9e:',len(data)/fs,'sec')\ndisplay(Audio(data,rate=fs))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## III. Manipulation de la fr\u00e9quence fondamentale (f0) par interpolation[\u00b6](#III.-Manipulation-de-la-fr%C3%A9quence-fondamentale-(f0)-par-interpolation)\n\n"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "source": "from scipy.interpolate import interp1d\n\n# Etirer le spectre d'amplitude avec le facteur \"a\"  (new f0= f0*a)  \ndef interpolate(spec, a):\n    n,m=spec.shape\n    newspec=np.zeros((n,m))\n    \n    for i in range(n):\n        f=interp1d(np.arange(m), spec[i,:])\n        new_x=np.arange(m)/a\n        new_x[new_x>m-1]=m-1\n        newspec[i,:]=f(new_x)\n    return newspec\n\n\n######## d\u00e9but du programme ####################\nfs, data = wavfile.read(\"fr.wav\") \nprint('Signal orginal: Freq \u00e9chantillonnage:',fs,'Hz, dur\u00e9e:',len(data)/fs,'sec')\ndisplay(Audio(data,rate=fs))\n\n\na=0.7\nspec=spectrogram(data, fs, p=16, T=512) \nspec[\"ampl\"]=interpolate(spec[\"ampl\"], a)\nnewdata, fs= spec2wav(spec)\nprint('Signal avec f0 manipul\u00e9 de %f'%a)\ndisplay(Audio(newdata,rate=fs))\n      \na=1.3\nspec=spectrogram(data, fs, p=16, T=512) \nspec[\"ampl\"]=interpolate(spec[\"ampl\"], a)\nnewdata, fs= spec2wav(spec)\nprint('Signal avec f0 manipul\u00e9 de %f'%a)\ndisplay(Audio(newdata,rate=fs))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Questions[\u00b6](#Questions)\n\n**Q1.** Essayez la manipulation sur les fichiers fr.wav, ar.wav, en.wav avec diff\u00e9rents param\u00e8tres \"a\" et d\u00e9duire l'impact de la valeur de \"a\" sur la parole\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## IV. Simulation du filtrage de l'oreille humaine (Echelle Mel)[\u00b6](#IV.-Simulation-du-filtrage-de-l'oreille-humaine-(Echelle-Mel))\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "### IV.1 Fonctions utiles[\u00b6](#IV.1-Fonctions-utiles)\n\n"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "source": "## Fonctions utiles de conversion\ndef Mel2Hz(mel): return 700 * (np.power(10,mel/2595)-1)\ndef Hz2Mel(freq): return 2595 * np.log10(1+freq/700)\ndef Hz2Ind(freq,fs,Tfft): return (freq*Tfft/fs).astype(int)\n\n#R\u00e9alisation de nf filtres sur l'\u00e9chelle Mel d'une fr\u00e9quence min \u00e0 une fr\u00e9quence max\ndef FiltresMel(fs, nf, Tfft, fmin, fmax):\n    Indices=Hz2Ind(Mel2Hz(np.linspace(Hz2Mel(fmin), Hz2Mel(min(fmax,fs/2)), nf+2)),fs,Tfft)\n    filtres=np.zeros((int(Tfft/2), nf))\n    for i in range(nf):\n        f=Indices[i+2]\n        if (Indices[i]-f)%2==0: f=min(f+1,int(Tfft/2))\n        if (f-Indices[i])>1: filtres[Indices[i]:f,i]=hamming(f-Indices[i])\n        else: filtres[Indices[i]:f,i]=1\n    return filtres", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### IV.2 Construction de filtres auditifs sur l'\u00e9chelle Mel et filtrage d'un spectrogramme[\u00b6](#IV.2-Construction-de-filtres-auditifs-sur-l'%C3%A9chelle-Mel-et-filtrage-d'un-spectrogramme)\n\n"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "source": "nf=20    #nombre de filtres\nT=256\nTfft=1024\nfs=8000\n\n#r\u00e9alisation des filtres auditifs\nfiltres=FiltresMel(fs, nf=nf, Tfft=Tfft, fmin=500, fmax=3500)\nplt.plot(filtres) \n#affichage des filtres\nplt.xticks(plt.xticks()[0][1:-1],np.round(plt.xticks()[0][1:-1]*fs/Tfft))\nplt.xlabel(\"Fr\u00e9quence (Hz)\")\nplt.title(\"%d Filtres auditifs\"%nf)\nplt.show()\n\n## Filtrage \nfilename=\"7_george_0.wav\"\nfs, data = wavfile.read(dataset_path+filename) \nspec=spectrogram(data, fs, T=T, Tfft=Tfft) #calcul du spectrogramme\nafficher(spec);  #affichage du spectrogramme\n\n#affichage de la sortie des filtres auditifs\nspec_filtre=(spec[\"ampl\"]@filtres)/10\nplt.pcolormesh(np.log(spec_filtre+1).T, cmap=\"gray_r\")\nplt.title(\"Spectrogramme filtr\u00e9 par %d filtres auditifs\"%nf)\nplt.ylabel(\"Sortie de chaque filtre\")\nplt.show()", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### IV.3 Compression de la parole par les filtres auditifs[\u00b6](#IV.3-Compression-de-la-parole-par-les-filtres-auditifs)\n\n**Objectif:** Ins\u00e9rer un maximum de z\u00e9ros en \u00e9liminant les sons qui ne sont pas per\u00e7us par l'oreille humaine\n\n"}, {"cell_type": "code", "execution_count": 0, "metadata": {}, "source": "nf=36    #nombre de filtres\nT=512\nfs, data = wavfile.read(\"fr.wav\") #chargement d'un fichier audio wav\n\n#Foncrion Compression du signal par les filtres auditifs\ndef Compression(spec, nf, fmin=200, fmax=4000):\n    filtres=FiltresMel(spec[\"fs\"], nf, spec[\"Tfft\"], fmin, fmax)\n    newspec=np.zeros(spec[\"ampl\"].shape)\n    for i in range(filtres.shape[1]):\n        ind=np.argmax(spec[\"ampl\"]*(filtres[:,i]>0),axis=1)\n        for j in range(len(ind)):  #ne grader que la valeur max de chaque bande de filtre\n            newspec[j, ind[j]]=spec[\"ampl\"][j, ind[j]]\n    return newspec\n\n\n################# d\u00e9but du programme #################\nprint('Signal orginal: Freq \u00e9chantillonnage:',fs,'Hz, dur\u00e9e:',len(data)/fs,'sec')\ndisplay(Audio(data,rate=fs))\nspec=spectrogram(data, fs, p=int(T/32), T=T) #calcul du spectrogramme \nafficher(spec)\nplt.show()\n\nnewspec=Compression(spec, nf=nf, fmin=0, fmax=8000)  #compression\nspec[\"ampl\"]=newspec  #remplacer le spectre d'amplitude par le spectre compress\u00e9\nnewdata, fs= spec2wav(spec)  #retour au domaine temporel\nprint(\"Signal compress\u00e9 avec %d filtres\"%nf)\ndisplay(Audio(newdata,rate=fs)) #\u00e9couter le r\u00e9sultat\nafficher(spec)", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Questions[\u00b6](#Questions)\n\nSachant que plus le nombre de filtres est petit, plus le son est compress\u00e9.  \n**Q1.** Essayez plusieurs param\u00e8tres nf, T, fmin, fmax, sur les fichier fr.wav, ar.wav, en.wav afin d'obtenir un bon taux de compression avec une bonne qualit\u00e9 de son.\n\n"}]}